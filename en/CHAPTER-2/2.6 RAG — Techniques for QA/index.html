
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://boramorka.github.io/LLM-book/en/CHAPTER-2/2.6%20RAG%20%E2%80%94%20Techniques%20for%20QA/">
      
      
        <link rel="prev" href="../2.5%20Semantic%20Search%20%E2%80%94%20Advanced%20Strategies/">
      
      
        <link rel="next" href="../2.7%20Chatbots%20with%20LangChain/">
      
      
        
          <link rel="alternate" href="../../" hreflang="en">
        
          <link rel="alternate" href="../../../ru/" hreflang="ru">
        
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.1">
    
    
      
        <title>2.6 RAG Systems. Techniques for Question Answering - LLMOps. Make AI Work For You.</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#26-rag-systems-techniques-for-qa" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="LLMOps. Make AI Work For You." class="md-header__button md-logo" aria-label="LLMOps. Make AI Work For You." data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            LLMOps. Make AI Work For You.
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              2.6 RAG Systems. Techniques for Question Answering
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
      <div class="md-header__option">
  <div class="md-select">
    
    <button class="md-header__button md-icon" aria-label="Select language">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m12.87 15.07-2.54-2.51.03-.03A17.5 17.5 0 0 0 14.07 6H17V4h-7V2H8v2H1v2h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2zm-2.62 7 1.62-4.33L19.12 17z"/></svg>
    </button>
    <div class="md-select__inner">
      <ul class="md-select__list">
        
          <li class="md-select__item">
            <a href="../../" hreflang="en" class="md-select__link">
              English
            </a>
          </li>
        
          <li class="md-select__item">
            <a href="../../../ru/" hreflang="ru" class="md-select__link">
              Русский
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</div>
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/boramorka/LLM-book" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    boramorka/LLM-book
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="LLMOps. Make AI Work For You." class="md-nav__button md-logo" aria-label="LLMOps. Make AI Work For You." data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    LLMOps. Make AI Work For You.
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/boramorka/LLM-book" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    boramorka/LLM-book
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    CHAPTER-1. OPEN AI API
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    CHAPTER-1. OPEN AI API
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CHAPTER-1/1.1%20Introduction/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    1.1 Introduction
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CHAPTER-1/1.2%20Classification/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    1.2 Classification
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CHAPTER-1/1.3%20Advanced%20Moderation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    1.3 Advanced Moderation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CHAPTER-1/1.4%20Advanced%20Machine%20Reasoning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    1.4 Elevating Machine Reasoning
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CHAPTER-1/1.5%20The%20Power%20of%20Prompt%20Chaining/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    1.5 The Power of Prompt Chaining
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CHAPTER-1/1.6%20Building%20and%20Evaluating%20LLM%20Applications/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    1.6 Building and Evaluating LLM Applications
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CHAPTER-1/1.7%20Takeaways%20and%20Reflections/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    1.7 Summary and Reflections
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    CHAPTER-2. LANGCHAIN
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    CHAPTER-2. LANGCHAIN
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2.1%20Introduction/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    2.1 Introduction
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2.2%20LangChain%20Document%20Loaders/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    2.2 LangChain Document Loaders
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2.3%20Deep%20Dive%20into%20Text%20Splitting/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    2.3 Deep Dive into Text Splitting
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2.4%20The%20Power%20of%20Embeddings/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    2.4 The Power of Embeddings
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2.5%20Semantic%20Search%20%E2%80%94%20Advanced%20Strategies/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    2.5 Semantic Search. Advanced Retrieval Strategies
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    2.6 RAG Systems. Techniques for Question Answering
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    2.6 RAG Systems. Techniques for Question Answering
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#conclusion" class="md-nav__link">
    <span class="md-ellipsis">
      
        Conclusion
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#further-reading" class="md-nav__link">
    <span class="md-ellipsis">
      
        Further Reading
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#theory-questions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Theory Questions
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#practical-tasks" class="md-nav__link">
    <span class="md-ellipsis">
      
        Practical Tasks
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2.7%20Chatbots%20with%20LangChain/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    2.7 Building Chatbots with LangChain
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2.8%20Takeaways%20and%20Reflections/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    2.8 Summary and Reflections
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    CHAPTER-3. LLMOPS
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    CHAPTER-3. LLMOPS
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CHAPTER-3/3.1%20Introduction/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    3.1 Introduction
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CHAPTER-3/3.2%20Workflow%20with%20Kubeflow%20Pipelines/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    3.2 Mastering LLM Workflows with Kubeflow Pipelines
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CHAPTER-3/3.3%20AI%20Quiz%20Generation%20Mechanism/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    3.3 Implementing the AI Quiz Generation Mechanism
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CHAPTER-3/3.4%20Takeaways%20and%20Reflections/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    3.4 Summary and Reflections
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Answers
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            
  
    Answers
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CHAPTER-1/Answers%201.1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    1.1 Introduction
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CHAPTER-1/Answers%201.2/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    1.2 Classification
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CHAPTER-1/Answers%201.3/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    1.3 Advanced Moderation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CHAPTER-1/Answers%201.4/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    1.4 Elevating Machine Reasoning
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CHAPTER-1/Answers%201.5/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    1.5 The Power of Prompt Chaining
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CHAPTER-1/Answers%201.6/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    1.6 Building and Evaluating LLM Applications
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Answers%202.2/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    2.2 LangChain Document Loaders
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Answers%202.3/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    2.3 Deep Dive into Text Splitting
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Answers%202.4/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    2.4 The Power of Embeddings
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Answers%202.5/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    2.5 Semantic Search. Advanced Retrieval Strategies
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Answers%202.6/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    2.6 RAG Systems. Techniques for Question Answering
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Answers%202.7/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    2.7 Building Chatbots with LangChain
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CHAPTER-3/Answers%203.2/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    3.2 Mastering LLM Workflows with Kubeflow Pipelines
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CHAPTER-3/Answers%203.3/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    3.3 Implementing the AI Quiz Generation Mechanism
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#conclusion" class="md-nav__link">
    <span class="md-ellipsis">
      
        Conclusion
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#further-reading" class="md-nav__link">
    <span class="md-ellipsis">
      
        Further Reading
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#theory-questions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Theory Questions
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#practical-tasks" class="md-nav__link">
    <span class="md-ellipsis">
      
        Practical Tasks
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="26-rag-systems-techniques-for-qa">2.6 RAG Systems — Techniques for QA</h1>
<p>Retrieval‑Augmented Generation (RAG) combines retrieval and generation, changing how we work with large corpora to build accurate QA systems and chatbots. A critical stage is feeding retrieved documents to the model along with the original query to generate an answer. After relevant materials are retrieved, they must be synthesized into a coherent answer that blends the content with the query’s context and leverages the model’s capabilities. The overall flow is simple: the system accepts a question; retrieves relevant fragments from a vector store; then feeds the retrieved content together with the question into an LLM to form an answer. By default, you can send all retrieved parts into context, but context‑window limits often lead to strategies like MapReduce, Refine, or Map‑Rerank — they aggregate or iteratively refine answers across many documents.</p>
<p>Before using an LLM for QA, ensure the environment is set up: imports, API keys, model versions, and so on.</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">OpenAI</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">dotenv</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dotenv</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">datetime</span>

<span class="c1"># Load environment variables and configure the OpenAI API key</span>
<span class="n">load_dotenv</span><span class="p">()</span>
<span class="n">client</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">()</span>

<span class="c1"># Configure LLM versioning</span>
<span class="n">current_date</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">date</span><span class="p">()</span>
<span class="n">llm_name</span> <span class="o">=</span> <span class="s2">&quot;gpt-3.5-turbo&quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using LLM version: </span><span class="si">{</span><span class="n">llm_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>
<p>Next, retrieve documents relevant to the query from a vector database (VectorDB), where embeddings are stored.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Import the vector store and embedding generator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain.vectorstores</span><span class="w"> </span><span class="kn">import</span> <span class="n">Chroma</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">OpenAIEmbeddings</span>

<span class="c1"># Directory where the vector database persists its data</span>
<span class="n">documents_storage_directory</span> <span class="o">=</span> <span class="s1">&#39;docs/chroma/&#39;</span>

<span class="c1"># Initialize the embedding generator using OpenAI embeddings</span>
<span class="n">embeddings_generator</span> <span class="o">=</span> <span class="n">OpenAIEmbeddings</span><span class="p">()</span>

<span class="c1"># Initialize the vector database with the persistence directory and embedding function</span>
<span class="n">vector_database</span> <span class="o">=</span> <span class="n">Chroma</span><span class="p">(</span><span class="n">persist_directory</span><span class="o">=</span><span class="n">documents_storage_directory</span><span class="p">,</span> <span class="n">embedding_function</span><span class="o">=</span><span class="n">embeddings_generator</span><span class="p">)</span>

<span class="c1"># Show the current number of documents in the vector database</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Documents in VectorDB: </span><span class="si">{</span><span class="n">vector_database</span><span class="o">.</span><span class="n">_collection</span><span class="o">.</span><span class="n">count</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>
<p><code>RetrievalQA</code> combines retrieval and generation: the LLM answers based on retrieved documents. First, initialize the language model,</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">langchain_openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatOpenAI</span>

<span class="c1"># Initialize the chat model with the selected LLM</span>
<span class="n">language_model</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">llm_name</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div>
<p>then configure the RetrievalQA chain with a custom prompt,</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Import required LangChain modules</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain.chains</span><span class="w"> </span><span class="kn">import</span> <span class="n">RetrievalQA</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain.prompts</span><span class="w"> </span><span class="kn">import</span> <span class="n">PromptTemplate</span>

<span class="c1"># Create a custom prompt template to guide the LLM to use the provided context effectively</span>
<span class="n">custom_prompt_template</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;To better assist with the inquiry, consider the details provided below as your reference...</span>
<span class="si">{context}</span>
<span class="s2">Inquiry: </span><span class="si">{question}</span>
<span class="s2">Insightful Response:&quot;&quot;&quot;</span>

<span class="c1"># Initialize the RetrievalQA chain with the custom prompt</span>
<span class="n">a_question_answering_chain</span> <span class="o">=</span> <span class="n">RetrievalQA</span><span class="o">.</span><span class="n">from_chain_type</span><span class="p">(</span>
    <span class="n">language_model</span><span class="p">,</span>
    <span class="n">retriever</span><span class="o">=</span><span class="n">vector_database</span><span class="o">.</span><span class="n">as_retriever</span><span class="p">(),</span>
    <span class="n">return_source_documents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">chain_type_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;prompt&quot;</span><span class="p">:</span> <span class="n">PromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span><span class="n">custom_prompt_template</span><span class="p">)}</span>
<span class="p">)</span>
</code></pre></div>
<p>and check the answer on a simple query.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Provide a sample query</span>
<span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;Is probability a class topic?&quot;</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">a_question_answering_chain</span><span class="p">({</span><span class="s2">&quot;query&quot;</span><span class="p">:</span> <span class="n">query</span><span class="p">})</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Answer:&quot;</span><span class="p">,</span> <span class="n">response</span><span class="p">[</span><span class="s2">&quot;result&quot;</span><span class="p">])</span>
</code></pre></div>
<p>Next come advanced QA chain types. MapReduce and Refine help work around context‑window limits when handling many documents: MapReduce aggregates in parallel, while Refine improves the answer sequentially.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Configure a QA chain to use MapReduce, aggregating answers from multiple documents</span>
<span class="n">question_answering_chain_map_reduce</span> <span class="o">=</span> <span class="n">RetrievalQA</span><span class="o">.</span><span class="n">from_chain_type</span><span class="p">(</span>
    <span class="n">language_model</span><span class="p">,</span>
    <span class="n">retriever</span><span class="o">=</span><span class="n">vector_database</span><span class="o">.</span><span class="n">as_retriever</span><span class="p">(),</span>
    <span class="n">chain_type</span><span class="o">=</span><span class="s2">&quot;map_reduce&quot;</span>
<span class="p">)</span>

<span class="c1"># Run MapReduce with the user query</span>
<span class="n">response_map_reduce</span> <span class="o">=</span> <span class="n">question_answering_chain_map_reduce</span><span class="p">({</span><span class="s2">&quot;query&quot;</span><span class="p">:</span> <span class="n">query</span><span class="p">})</span>

<span class="c1"># Show the aggregated answer</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MapReduce answer:&quot;</span><span class="p">,</span> <span class="n">response_map_reduce</span><span class="p">[</span><span class="s2">&quot;result&quot;</span><span class="p">])</span>

<span class="c1"># Configure a QA chain to use Refine, which iteratively improves the answer</span>
<span class="n">question_answering_chain_refine</span> <span class="o">=</span> <span class="n">RetrievalQA</span><span class="o">.</span><span class="n">from_chain_type</span><span class="p">(</span>
    <span class="n">language_model</span><span class="p">,</span>
    <span class="n">retriever</span><span class="o">=</span><span class="n">vector_database</span><span class="o">.</span><span class="n">as_retriever</span><span class="p">(),</span>
    <span class="n">chain_type</span><span class="o">=</span><span class="s2">&quot;refine&quot;</span>
<span class="p">)</span>

<span class="c1"># Run Refine with the same user query</span>
<span class="n">response_refine</span> <span class="o">=</span> <span class="n">question_answering_chain_refine</span><span class="p">({</span><span class="s2">&quot;query&quot;</span><span class="p">:</span> <span class="n">query</span><span class="p">})</span>

<span class="c1"># Show the refined answer</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Refine answer:&quot;</span><span class="p">,</span> <span class="n">response_refine</span><span class="p">[</span><span class="s2">&quot;result&quot;</span><span class="p">])</span>
</code></pre></div>
<p>In practice, consider: choose between MapReduce and Refine based on the task (the former for fast aggregation from many sources; the latter for higher accuracy and iterative improvement); in distributed systems, performance depends on network latency and serialization; effectiveness varies with data, so experiment.</p>
<p>One notable limitation of RetrievalQA is the lack of dialogue history, which degrades handling of follow‑up questions. Demonstration of the limitation:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Import a QA chain from a hypothetical library</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">some_library</span><span class="w"> </span><span class="kn">import</span> <span class="n">question_answering_chain</span> <span class="k">as</span> <span class="n">qa_chain</span>

<span class="c1"># Define an initial question related to course content</span>
<span class="n">initial_question_about_course_content</span> <span class="o">=</span> <span class="s2">&quot;Does the curriculum cover probability theory?&quot;</span>
<span class="c1"># Generate an answer to the initial question</span>
<span class="n">response_to_initial_question</span> <span class="o">=</span> <span class="n">qa_chain</span><span class="p">({</span><span class="s2">&quot;query&quot;</span><span class="p">:</span> <span class="n">initial_question_about_course_content</span><span class="p">})</span>

<span class="c1"># Define a follow‑up question without explicitly preserving conversation context</span>
<span class="n">follow_up_question_about_prerequisites</span> <span class="o">=</span> <span class="s2">&quot;Why are those prerequisites important?&quot;</span>
<span class="c1"># Generate an answer to the follow‑up question</span>
<span class="n">response_to_follow_up_question</span> <span class="o">=</span> <span class="n">qa_chain</span><span class="p">({</span><span class="s2">&quot;query&quot;</span><span class="p">:</span> <span class="n">follow_up_question_about_prerequisites</span><span class="p">})</span>

<span class="c1"># Display both answers — initial and follow‑up</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Answer to the initial question:&quot;</span><span class="p">,</span> <span class="n">response_to_initial_question</span><span class="p">[</span><span class="s2">&quot;result&quot;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Answer to the follow‑up question:&quot;</span><span class="p">,</span> <span class="n">response_to_follow_up_question</span><span class="p">[</span><span class="s2">&quot;result&quot;</span><span class="p">])</span>
</code></pre></div>
<p>This underscores the importance of integrating conversation memory into RAG systems.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Advanced QA techniques in RAG deliver more dynamic and accurate answers. A careful <code>RetrievalQA</code> implementation and handling of its limitations enable building systems capable of substantive dialogue with users.</p>
<h2 id="further-reading">Further Reading</h2>
<ul>
<li>Explore the latest advances in LLMs and their impact on RAG.</li>
<li>Investigate strategies for integrating conversation memory into RAG frameworks.</li>
</ul>
<p>This chapter provides a foundation for understanding and practicing advanced QA techniques in RAG and for further innovation in AI interactions.</p>
<h2 id="theory-questions">Theory Questions</h2>
<ol>
<li>Name the three stages of QA in RAG.</li>
<li>What are context‑window limits, and how do MapReduce/Refine help work around them?</li>
<li>Why is a vector database (VectorDB) needed for retrieval in RAG?</li>
<li>How does <code>RetrievalQA</code> combine retrieval and generation?</li>
<li>Compare the MapReduce and Refine approaches.</li>
<li>Which practical factors matter in distributed systems (network latency, serialization)?</li>
<li>Why is it important to experiment with both approaches?</li>
<li>How does missing dialogue history affect handling of follow‑up questions?</li>
<li>Why integrate conversation memory into RAG?</li>
<li>What should be studied next to deepen RAG expertise?</li>
</ol>
<h2 id="practical-tasks">Practical Tasks</h2>
<ol>
<li>Initialize a vector DB (Chroma + OpenAIEmbeddings) and print the number of documents it contains.</li>
<li>Configure <code>RetrievalQA</code> with a custom prompt, specifying the model and the data storage directory.</li>
<li>Demonstrate <code>MapReduce</code> and <code>Refine</code> on a single query and print the resulting answers.</li>
<li>Simulate a follow‑up question without preserving dialogue context to show the <code>RetrievalQA</code> limitation.</li>
</ol>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../..", "features": ["navigation.sections", "navigation.expand", "navigation.indexes", "navigation.top", "search.suggest", "search.highlight", "content.tabs.link", "content.code.annotation", "content.code.copy"], "search": "../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.79ae519e.min.js"></script>
      
    
  </body>
</html>