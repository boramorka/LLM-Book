# Ответы 3.2

## Теория
1. Kubeflow Pipelines автоматизируют ML-воркфлоу, обеспечивая воспроизводимость и экономию времени за счет эффективного управления сложными пайплайнами.
2. Модуль `dsl` предоставляет декораторы и классы для определения компонентов и структуры пайплайна, а `compiler` отвечает за компиляцию пайплайна в формат, пригодный для исполнения движком Kubeflow.
3. Предупреждения `FutureWarning` можно выборочно подавлять для улучшения читабельности логов, при этом важно продолжать следить за изменениями в документации и актуализировать код.
4. Четко определенные интерфейсы и возможность повторного использования компонентов упрощают интеграцию, повышая модульность и общую эффективность системы.
5. Декоратор `@dsl.component` помечает функцию как компонент пайплайна, который является изолированным и многократно используемым шагом в рабочем процессе.
6. Вызов компонента возвращает объект `PipelineTask`, который представляет собой экземпляр выполнения шага пайплайна и используется для передачи данных между компонентами.
7. Вывод данных из компонента передается через атрибут `.output` объекта `PipelineTask`.
8. Использование именованных аргументов повышает ясность кода и помогает предотвратить ошибки, особенно при работе с большим количеством входных параметров.
9. При связывании компонентов в пайплайне необходимо передавать `.output` одного компонента в качестве входа для другого, чтобы обеспечить корректный поток данных.
10. Пайплайн объявляется с помощью декоратора `@dsl.pipeline` и отвечает за оркестрацию компонентов. Важными аспектами являются среда исполнения и правильная обработка выходов.
11. Компиляция пайплайна — это процесс преобразования его Python-определения в файл YAML, который затем может быть загружен и запущен в целевой среде Kubeflow.
12. Повторное использование готовых пайплайнов (например, PEFT для PaLM 2) значительно ускоряет разработку и помогает поддерживать лучшие практики.
13. Версионирование модели критически важно для MLOps, обеспечивая воспроизводимость и возможность аудита. Например, можно добавить дату и время к имени модели.
14. Аргументы пайплайна задают входные данные и конфигурацию для тонкой настройки, что крайне важно для его корректного запуска.
15. Автоматизация и оркестрация в Kubeflow повышают эффективность и масштабируемость, однако требуют тщательного планирования и глубокого понимания компонентов и потока данных.

## Практика
Решения для заданий:

### 1. Настройка Kubeflow Pipelines SDK

```python
# Импортируем необходимые модули из SDK Kubeflow Pipelines
from kfp import dsl, compiler

# Подавляем предупреждения FutureWarning из SDK Kubeflow Pipelines
import warnings
warnings.filterwarnings("ignore", category=FutureWarning, module='kfp.*')
```

Этот скрипт импортирует `dsl` и `compiler`, а также подавляет предупреждения `FutureWarning` из модулей `kfp.*`.

### 2. Определение простого компонента пайплайна

```python
from kfp import dsl

# Определяем простой компонент для сложения двух чисел
@dsl.component
def add_numbers(num1: int, num2: int) -> int:
    return num1 + num2
```

Функция-компонент `add_numbers`, помеченная декоратором `@dsl.component`, принимает два целочисленных значения и возвращает их сумму.

### 3. Подавление определенных предупреждений

```python
import warnings
warnings.filterwarnings("ignore", category=DeprecationWarning)
```

Этот скрипт подавляет предупреждения `DeprecationWarning` для всех модулей.

### 4. Связывание компонентов в пайплайне

```python
from kfp import dsl

# Компонент для генерации фиксированного числа
@dsl.component
def generate_number() -> int:
    return 42

# Компонент для удвоения числа, полученного на входе
@dsl.component
def double_number(input_number: int) -> int:
    return input_number * 2

# Определяем пайплайн, который связывает два компонента
@dsl.pipeline(
    name="Number doubling pipeline",
    description="A pipeline that generates a number and doubles it."
)
def number_doubling_pipeline():
    # Шаг 1: Генерируем число
    generated_number_task = generate_number()

    # Шаг 2: Удваиваем сгенерированное число
    double_number_task = double_number(input_number=generated_number_task.output)
```

Пайплайн состоит из двух компонентов: `generate_number`, который генерирует фиксированное число, и `double_number`, который удваивает входное значение. Связь между ними устанавливается путем передачи `.output` первого компонента в качестве входа для второго.

### 5. Компиляция и подготовка пайплайна к выполнению

```python
from kfp import compiler

# Предполагаем, что определение пайплайна называется number_doubling_pipeline
pipeline_func = number_doubling_pipeline

# Компилируем пайплайн
compiler.Compiler().compile(
    pipeline_func=pipeline_func,
    package_path='number_doubling_pipeline.yaml'
)
```

Пайплайн компилируется в файл `number_doubling_pipeline.yaml`, который можно загрузить и запустить в среде Kubeflow.

### 6. Работа с объектами `PipelineTask`

```python
# Это гипотетическая функция, которая не может быть выполнена «как есть». Она предназначена для иллюстрации концепции.
def handle_pipeline_task():
    # Гипотетический вызов функции компонента с именем my_component
    # В реальном сценарии это должно происходить внутри функции пайплайна
    task = my_component(param1="value")

    # Доступ к выводу компонента
    # Эта строка является иллюстративной и обычно используется для передачи выходных данных между компонентами в пайплайне
    output = task.output

    print("Доступ к выводу компонента:", output)

# Примечание: В реальном использовании my_component будет определен как компонент Kubeflow Pipeline,
# а манипуляции с задачами должны происходить в контексте функции пайплайна.
```

Пример демонстрирует, что вызов компонента возвращает объект `PipelineTask`, а доступ к его результату осуществляется через `task.output`. В реальных условиях работа с такими объектами происходит внутри функции-пайплайна.

### 7. Обработка ошибок в определениях пайплайнов

```python
from kfp import dsl

# Некорректное определение пайплайна
@dsl.pipeline(
    name='Incorrect Pipeline',
    description='An example that attempts to return a PipelineTask object directly.'
)
def incorrect_pipeline_example():
    @dsl.component
    def generate_number() -> int:
        return 42

    generated_number_task = generate_number()
    # Некорректная попытка вернуть объект PipelineTask напрямую
    return generated_number_task  # Это приведет к ошибке

# Корректное определение пайплайна
@dsl.pipeline(
    name='Correct Pipeline',
    description='A corrected example that does not attempt to return a PipelineTask object.'
)
def correct_pipeline_example():
    @dsl.component
    def generate_number() -> int:
        return 42

    generated_number_task = generate_number()
    # Корректный подход: не пытайтесь возвращать объект PipelineTask напрямую из функции пайплайна.
    # Функция пайплайна не должна ничего возвращать.

# Пояснение: функция пайплайна оркестрирует шаги и поток данных, но не возвращает данные напрямую.
# Попытка вернуть объект PipelineTask из функции пайплайна некорректна, поскольку определение пайплайна
# должно описывать структуру и зависимости компонентов, а не напрямую обрабатывать данные.
# Исправленная версия удаляет оператор return, что соответствует ожидаемому поведению функций пайплайна.
```

### 8. Автоматизация подготовки данных для обучения модели

```python
import json

# Имитация подготовки данных для обучения модели
def preprocess_data(input_file_path, output_file_path):
    # Чтение данных из JSON-файла
    with open(input_file_path, 'r') as infile:
        data = json.load(infile)

    # Выполнение простого преобразования: фильтрация данных
    # Для иллюстрации предположим, что нам нужны только элементы с определенным условием
    # Например, фильтрация элементов, где значение "useful" равно True
    filtered_data = [item for item in data if item.get("useful", False)]

    # Сохранение преобразованных данных в другой JSON-файл
    with open(output_file_path, 'w') as outfile:
        json.dump(filtered_data, outfile, indent=4)

# Пример использования
preprocess_data('input_data.json', 'processed_data.json')

# Примечание: Этот скрипт предполагает наличие файла 'input_data.json' в текущем каталоге
# и сохранит обработанные данные в 'processed_data.json'.
# В реальном сценарии пути и логика преобразования должны быть скорректированы в соответствии с конкретными требованиями.
```

Этот скрипт демонстрирует простой процесс подготовки данных: чтение данных из JSON-файла, выполнение преобразования (в данном случае, фильтрация по условию) и сохранение обработанных данных в другой JSON-файл. Этот тип задачи можно инкапсулировать в компонент Kubeflow Pipeline для автоматизации шагов подготовки данных в рабочих процессах обучения ML-моделей.

### 9. Реализация версионирования моделей в пайплайне

```python
from datetime import datetime

def generate_model_name(base_model_name: str) -> str:
    # Генерация временной метки в формате "YYYYMMDD-HHMMSS"
    timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
    # Добавление временной метки к базовому имени модели для создания уникального имени
    model_name = f"{base_model_name}-{timestamp}"
    return model_name

# Пример использования
base_model_name = "my_model"
model_name = generate_model_name(base_model_name)
print("Сгенерированное имя модели:", model_name)

# Эта функция генерирует уникальное имя модели путем добавления текущей даты и времени к базовому имени модели.
# Такая практика помогает в версионировании моделей, облегчая отслеживание и управление различными версиями моделей в операциях машинного обучения.
```

### 10. Параметризация и выполнение пайплайна Kubeflow

Для целей этой задачи предположим, что мы работаем в среде, где у нас есть доступ к API выполнения Kubeflow Pipeline. Поскольку фактические детали выполнения могут варьироваться в зависимости от конкретной платформы и версии API, этот скрипт представляет гипотетический пример, основанный на общих паттернах.

```python
# Предполагается наличие необходимых импортов и конфигураций для взаимодействия со средой выполнения

def submit_pipeline_execution(compiled_pipeline_path: str, pipeline_arguments: dict):
    # Заполнитель для метода API или SDK для отправки пайплайна на выполнение
    # В реальном сценарии это будет включать использование SDK Kubeflow Pipelines или SDK облачного провайдера
    # Например, использование SDK Kubeflow Pipelines или облачного сервиса, такого как Google Cloud AI Platform Pipelines

    # Предполагается, что функция `submit_pipeline_job` существует и может быть использована для отправки
    # Эта функция будет частью SDK или API среды выполнения
    submit_pipeline_job(compiled_pipeline_path, pipeline_arguments)

# Пример аргументов пайплайна
pipeline_arguments = {
    "recipient_name": "Alice"
}

# Путь к скомпилированному YAML-файлу пайплайна Kubeflow
compiled_pipeline_path = "path_to_compiled_pipeline.yaml"

# Отправка пайплайна на выполнение
submit_pipeline_execution(compiled_pipeline_path, pipeline_arguments)

# Примечание: Этот пример предполагает существование функции `submit_pipeline_job`, которая будет специфичной
# для API или SDK среды выполнения. В реальной реализации вы замените этот заполнитель
# фактическим кодом для взаимодействия с API Kubeflow Pipelines или API управляемого сервиса, такого как Google Cloud AI Platform.
```

Этот скрипт описывает, как можно параметризовать и отправить скомпилированный пайплайн Kubeflow на выполнение, предполагая наличие подходящего метода API или SDK (`submit_pipeline_job` в этом гипотетическом примере). Фактический метод отправки задания будет зависеть от специфики вашей среды выполнения или поставщика облачных услуг.
