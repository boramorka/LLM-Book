# Ответы 1.3

## Теория

1. Интеграция OpenAI Moderation API: получите API-ключ, подключите клиентскую библиотеку на бэкенде и встройте проверку в цепочку подачи контента, чтобы анализировать все данные до публикации.
2. Кастомизация: настройте чувствительность, сфокусируйтесь на определённых нарушениях, используйте собственные списки разрешённых/запрещённых элементов (allow/deny-листы) в соответствии со стандартами сообщества и требованиями комплаенса.
3. Расширение модерации: помимо текста, добавьте проверку изображений и видео (используя инструменты OpenAI или сторонние решения) для обеспечения комплексной защиты.
4. Разделители (delimiters) снижают риск prompt-инъекций, отделяя ввод пользователя от системных инструкций и сохраняя целостность команд.
5. Изоляция команд с помощью разделителей чётко отделяет исполняемые команды от пользовательских данных и предотвращает внедрение вредоносных инструкций.
6. Дополнительные меры: строгая валидация ввода, принцип наименьших привилегий, allow-листы, регулярные выражения, мониторинг и логирование для выявления аномалий.
7. Прямая оценка: попросите модель классифицировать ввод как попытку инъекции или нет — это снижает количество ложных срабатываний и повышает точность реакции.
8. Ответные меры: оповещение и обучение пользователей, просьба переформулировать запрос, изоляция подозрительного контента и его ревью человеком, а также динамическая настройка чувствительности системы.
9. Плюсы и минусы прямой оценки: точность и адаптивность против сложности разработки и поддержки, а также необходимости баланса между безопасностью и удобством использования (UX).
10. Совмещение Moderation API и стратегий против инъекций существенно повышает безопасность и целостность платформ, работающих с пользовательским контентом (UGC).

## Практика (эскизы)

1. Функция модерации одного фрагмента текста:
```python
from openai import OpenAI

client = OpenAI()

def moderate_content(content: str) -> bool:
    resp = client.moderations.create(model="omni-moderation-latest", input=content)
    return bool(resp.results[0].flagged)
```

2. Удаление разделителя из строки:
```python
def sanitize_delimiter(input_text: str, delimiter: str) -> str:
    return input_text.replace(delimiter, "")
```

3. Проверка длины ввода:
```python
def validate_input_length(input_text: str, min_length=1, max_length=200) -> bool:
    return min_length <= len(input_text) <= max_length
```

4. Сессия пользователя с простыми эвристиками:
```python
class UserSession:
    def __init__(self, user_id: int):
        self.user_id = user_id
        self.trust_level = 0
        self.sensitivity_level = 5

    def adjust_sensitivity(self):
        if self.trust_level > 5:
            self.sensitivity_level = max(1, self.sensitivity_level - 1)
        else:
            self.sensitivity_level = min(10, self.sensitivity_level + 1)

    def evaluate_input(self, user_input: str) -> bool:
        dangerous_keywords = ["exec", "delete", "drop"]
        return any(k in user_input.lower() for k in dangerous_keywords)

    def handle_input(self, user_input: str):
        if self.evaluate_input(user_input):
            if self.trust_level < 5:
                print("Ввод помечен и отправлен на проверку безопасностью.")
            else:
                print("Запрос выглядит подозрительно. Уточните или переформулируйте, пожалуйста.")
        else:
            print("Ввод принят. Спасибо!")
        print("Помните: ввод должен быть ясным и без потенциально опасных команд.")
```

5. Прямая оценка на предмет инъекций (фиктивная логика):
```python
def direct_evaluation_for_injection(user_input: str) -> str:
    if "ignore instructions" in user_input.lower() or "disregard previous guidelines" in user_input.lower():
        return 'Y'
    return 'N'
```

6. Пример интеграции в основной цикл:
```python
if __name__ == "__main__":
    session = UserSession(user_id=1)
    while True:
        text = input("Введите текст (или 'exit'): ")
        if text.lower() == 'exit':
            break

        text = sanitize_delimiter(text, "####")
        if not validate_input_length(text):
            print("Ввод слишком короткий/длинный.")
            continue

        if moderate_content(text):
            print("Контент помечен как неприемлемый. Измените формулировку.")
            continue

        if direct_evaluation_for_injection(text) == 'Y':
            print("Обнаружена потенциальная инъекция. Переформулируйте, пожалуйста.")
            continue

        session.handle_input(text)
```

