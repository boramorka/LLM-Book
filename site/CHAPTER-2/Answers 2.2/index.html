
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.17">
    
    
      
        <title>Answers 2.2 - LLMOps. Make AI Work For You.</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.7e37652d.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#answers-22" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="LLMOps. Make AI Work For You." class="md-header__button md-logo" aria-label="LLMOps. Make AI Work For You." data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            LLMOps. Make AI Work For You.
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Answers 2.2
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
      <div class="md-header__option">
  <div class="md-select">
    
    <button class="md-header__button md-icon" aria-label="Select language">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m12.87 15.07-2.54-2.51.03-.03A17.5 17.5 0 0 0 14.07 6H17V4h-7V2H8v2H1v2h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2zm-2.62 7 1.62-4.33L19.12 17z"/></svg>
    </button>
    <div class="md-select__inner">
      <ul class="md-select__list">
        
          <li class="md-select__item">
            <a href="../../en/" hreflang="en" class="md-select__link">
              English
            </a>
          </li>
        
          <li class="md-select__item">
            <a href="../../ru/" hreflang="ru" class="md-select__link">
              Русский
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</div>
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/boramorka/LLM-book" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    boramorka/LLM-book
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



  

<nav class="md-nav md-nav--primary md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="LLMOps. Make AI Work For You." class="md-nav__button md-logo" aria-label="LLMOps. Make AI Work For You." data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    LLMOps. Make AI Work For You.
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/boramorka/LLM-book" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    boramorka/LLM-book
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="answers-22">Answers 2.2</h1>
<h2 id="theory">Theory</h2>
<ol>
<li>
<p>Document loaders in LangChain are specialized components designed to facilitate the access and conversion of data from various formats and sources into a standardized document object. They play a crucial role in enabling seamless integration and processing of diverse data types (like PDFs, HTML, and JSON) within LangChain applications, particularly for data-driven applications with conversational interfaces and Large Language Models.</p>
</li>
<li>
<p>Unstructured data loaders are adept at handling data from public and proprietary sources such as YouTube, Twitter, Figma, and Notion, dealing with a broad spectrum of unstructured data. Structured data loaders, on the other hand, are tailored for applications involving tabular data, supporting sources like Airbyte, Stripe, and Airtable to enable semantic search and question-answering over structured datasets.</p>
</li>
<li>
<p>The process involves installing necessary packages, setting up API keys for services like OpenAI, and loading environment variables from a <code>.env</code> file. This setup ensures that the environment is correctly configured to interact with external data sources through LangChain document loaders.</p>
</li>
<li>
<p>The PyPDFLoader in LangChain loads PDF documents by initializing with the path to the PDF file and then loading the document pages. It facilitates the extraction, cleaning, and tokenization of text from PDFs, enabling further processing such as word frequency analysis and handling of special cases like blank pages.</p>
</li>
<li>
<p>Text cleaning and tokenization involve removing non-alphabetic characters and splitting the text into lowercase words for basic normalization. This process is crucial for preparing the text for analysis, improving the accuracy of operations like word frequency counts and enabling more effective data processing and insight extraction.</p>
</li>
<li>
<p>The process involves initializing a Generic Loader with the YouTube Audio Loader and Whisper Parser, loading the document, and then accessing the transcribed content. This setup allows for the transcription of YouTube videos into text, using OpenAI's Whisper model for accurate audio to text conversion.</p>
</li>
<li>
<p>Sentence tokenization breaks down the transcribed text into individual sentences, enabling detailed analysis or processing. Sentiment analysis, performed using tools like TextBlob, assesses the overall tone and subjectivity of the video content, providing insights into the emotional and subjective content of the transcriptions.</p>
</li>
<li>
<p>Web content is loaded using the WebBaseLoader, which takes a target URL as input and loads the content. The content is then processed using tools like BeautifulSoup to parse HTML, clean the web content by removing unwanted elements, and extract specific information like hyperlinks and headings.</p>
</li>
<li>
<p>The process involves cleaning the web content to improve readability and analysis potential, extracting specific information like hyperlinks and headings, and summarizing the content through sentence tokenization, stopword filtering, and word frequency analysis to provide a concise summary of the web content.</p>
</li>
<li>
<p>The NotionDirectoryLoader loads data from a Notion database exported as Markdown. It converts Markdown to HTML for easier parsing, extracts structured data like headings and links, organizes the data into a DataFrame for analysis, and allows for filtering and summarizing based on the content and metadata.</p>
</li>
<li>
<p>Best practices include optimizing API usage to avoid unexpected costs, preprocessing data after loading to ensure it is in a usable format for further analysis or model training, and contributing to open-source projects like LangChain by developing new loaders for unsupported data sources.</p>
</li>
<li>
<p>Contributing new document loaders to the LangChain project can expand its capabilities, enabling support for a wider range of data sources and formats. This not only benefits the broader community by providing more tools for data processing and analysis but also enhances the contributor's understanding and expertise in handling diverse data types.</p>
</li>
</ol>
<h2 id="practice">Practice</h2>
<p>1.
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">langchain.document_loaders</span><span class="w"> </span><span class="kn">import</span> <span class="n">PyPDFLoader</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">re</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">nltk</span>

<span class="c1"># Download the list of stopwords from NLTK</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;stopwords&#39;</span><span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">nltk.corpus</span><span class="w"> </span><span class="kn">import</span> <span class="n">stopwords</span>

<span class="c1"># Initialize the list of English stopwords</span>
<span class="n">stop_words</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s1">&#39;english&#39;</span><span class="p">))</span>

<span class="c1"># Initialize the PDF Loader with the path to the PDF document</span>
<span class="n">pdf_loader</span> <span class="o">=</span> <span class="n">PyPDFLoader</span><span class="p">(</span><span class="s2">&quot;path/to/your/document.pdf&quot;</span><span class="p">)</span>

<span class="c1"># Load the document pages</span>
<span class="n">document_pages</span> <span class="o">=</span> <span class="n">pdf_loader</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>

<span class="c1"># Function to clean, tokenize, and remove stopwords from text</span>
<span class="k">def</span><span class="w"> </span><span class="nf">clean_tokenize_and_remove_stopwords</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\b[a-z]+\b&#39;</span><span class="p">,</span> <span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>  <span class="c1"># Tokenize and convert to lowercase</span>
    <span class="n">filtered_words</span> <span class="o">=</span> <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span> <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stop_words</span><span class="p">]</span>  <span class="c1"># Remove stopwords</span>
    <span class="k">return</span> <span class="n">filtered_words</span>

<span class="c1"># Initialize a Counter object for word frequencies</span>
<span class="n">word_frequencies</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>

<span class="c1"># Iterate over each page in the document</span>
<span class="k">for</span> <span class="n">page</span> <span class="ow">in</span> <span class="n">document_pages</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">page</span><span class="o">.</span><span class="n">page_content</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>  <span class="c1"># Check if the page is not blank</span>
        <span class="n">words</span> <span class="o">=</span> <span class="n">clean_tokenize_and_remove_stopwords</span><span class="p">(</span><span class="n">page</span><span class="o">.</span><span class="n">page_content</span><span class="p">)</span>
        <span class="n">word_frequencies</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>

<span class="c1"># Print the top 5 most common words not including stopwords</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Top 5 most common words excluding stopwords:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">freq</span> <span class="ow">in</span> <span class="n">word_frequencies</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">freq</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></p>
<p>2.
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">langchain.document_loaders.generic</span><span class="w"> </span><span class="kn">import</span> <span class="n">GenericLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain.document_loaders.parsers</span><span class="w"> </span><span class="kn">import</span> <span class="n">OpenAIWhisperParser</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain.document_loaders.blob_loaders.youtube_audio</span><span class="w"> </span><span class="kn">import</span> <span class="n">YoutubeAudioLoader</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">nltk</span>

<span class="c1"># Make sure nltk resources are downloaded (e.g., punkt for sentence tokenization)</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;punkt&#39;</span><span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">nltk.tokenize</span><span class="w"> </span><span class="kn">import</span> <span class="n">word_tokenize</span>

<span class="k">def</span><span class="w"> </span><span class="nf">transcribe_youtube_video</span><span class="p">(</span><span class="n">video_url</span><span class="p">):</span>
    <span class="c1"># Directory where audio files will be saved temporarily</span>
    <span class="n">audio_save_directory</span> <span class="o">=</span> <span class="s2">&quot;temp_audio/&quot;</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># Initialize the loader with YouTube Audio Loader and Whisper Parser</span>
        <span class="n">youtube_loader</span> <span class="o">=</span> <span class="n">GenericLoader</span><span class="p">(</span>
            <span class="n">YoutubeAudioLoader</span><span class="p">([</span><span class="n">video_url</span><span class="p">],</span> <span class="n">audio_save_directory</span><span class="p">),</span>
            <span class="n">OpenAIWhisperParser</span><span class="p">()</span>
        <span class="p">)</span>

        <span class="c1"># Load the document (transcription)</span>
        <span class="n">youtube_documents</span> <span class="o">=</span> <span class="n">youtube_loader</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>

        <span class="c1"># Access the transcribed content</span>
        <span class="n">transcribed_text</span> <span class="o">=</span> <span class="n">youtube_documents</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">page_content</span>

        <span class="c1"># Tokenize the transcribed text and return the first 100 words</span>
        <span class="n">first_100_words</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">transcribed_text</span><span class="p">)[:</span><span class="mi">100</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">first_100_words</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;An error occurred: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">None</span>

<span class="c1"># Example usage</span>
<span class="n">video_url</span> <span class="o">=</span> <span class="s2">&quot;https://www.youtube.com/watch?v=example_video_id&quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="n">transcribe_youtube_video</span><span class="p">(</span><span class="n">video_url</span><span class="p">))</span>
</code></pre></div></p>
<p>3.
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">requests</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">bs4</span><span class="w"> </span><span class="kn">import</span> <span class="n">BeautifulSoup</span>

<span class="k">def</span><span class="w"> </span><span class="nf">load_and_clean_web_content</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># Fetch the content from the URL</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
        <span class="n">response</span><span class="o">.</span><span class="n">raise_for_status</span><span class="p">()</span>  <span class="c1"># Raises an HTTPError if the status is 4xx, 5xx</span>

        <span class="c1"># Use BeautifulSoup to parse the HTML content</span>
        <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="s1">&#39;html.parser&#39;</span><span class="p">)</span>

        <span class="c1"># Get clean text by removing all HTML tags</span>
        <span class="n">clean_text</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">get_text</span><span class="p">(</span><span class="n">separator</span><span class="o">=</span><span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="n">strip</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Print the cleaned text</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">clean_text</span><span class="p">)</span>
    <span class="k">except</span> <span class="n">requests</span><span class="o">.</span><span class="n">exceptions</span><span class="o">.</span><span class="n">RequestException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Request failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;An error occurred during parsing: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Example usage</span>
<span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;https://example.com&quot;</span>
<span class="n">load_and_clean_web_content</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
</code></pre></div></p>
<p>4.
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">markdown</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">bs4</span><span class="w"> </span><span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>

<span class="k">def</span><span class="w"> </span><span class="nf">convert_md_to_html_and_extract_links</span><span class="p">(</span><span class="n">directory_path</span><span class="p">):</span>
    <span class="c1"># List all Markdown files in the directory</span>
    <span class="k">for</span> <span class="n">filename</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">directory_path</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">filename</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.md&quot;</span><span class="p">):</span>
            <span class="c1"># Construct the full file path</span>
            <span class="n">file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">directory_path</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>

            <span class="c1"># Read the Markdown file</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">md_file</span><span class="p">:</span>
                <span class="n">md_content</span> <span class="o">=</span> <span class="n">md_file</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

            <span class="c1"># Convert Markdown to HTML</span>
            <span class="n">html_content</span> <span class="o">=</span> <span class="n">markdown</span><span class="o">.</span><span class="n">markdown</span><span class="p">(</span><span class="n">md_content</span><span class="p">)</span>

            <span class="c1"># Use BeautifulSoup to parse HTML content</span>
            <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">html_content</span><span class="p">,</span> <span class="s1">&#39;html.parser&#39;</span><span class="p">)</span>

            <span class="c1"># Extract and print all links</span>
            <span class="n">links</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="n">href</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Links in </span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">link</span> <span class="ow">in</span> <span class="n">links</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Text: </span><span class="si">{</span><span class="n">link</span><span class="o">.</span><span class="n">text</span><span class="si">}</span><span class="s2">, Href: </span><span class="si">{</span><span class="n">link</span><span class="p">[</span><span class="s1">&#39;href&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------&quot;</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>  <span class="c1"># Separator for clarity</span>

<span class="c1"># Example usage</span>
<span class="n">directory_path</span> <span class="o">=</span> <span class="s2">&quot;path/to/your/notion/data&quot;</span>
<span class="n">convert_md_to_html_and_extract_links</span><span class="p">(</span><span class="n">directory_path</span><span class="p">)</span>
</code></pre></div></p>
<p>5.
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">textblob</span><span class="w"> </span><span class="kn">import</span> <span class="n">TextBlob</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain.document_loaders.generic</span><span class="w"> </span><span class="kn">import</span> <span class="n">GenericLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain.document_loaders.parsers</span><span class="w"> </span><span class="kn">import</span> <span class="n">OpenAIWhisperParser</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain.document_loaders.blob_loaders.youtube_audio</span><span class="w"> </span><span class="kn">import</span> <span class="n">YoutubeAudioLoader</span>

<span class="k">def</span><span class="w"> </span><span class="nf">transcribe_and_analyze_sentiment</span><span class="p">(</span><span class="n">video_url</span><span class="p">):</span>
    <span class="c1"># Directory where audio files will be temporarily saved</span>
    <span class="n">audio_save_directory</span> <span class="o">=</span> <span class="s2">&quot;temp_audio/&quot;</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># Initialize loader with YouTube Audio Loader and Whisper Parser</span>
        <span class="n">youtube_loader</span> <span class="o">=</span> <span class="n">GenericLoader</span><span class="p">(</span>
            <span class="n">YoutubeAudioLoader</span><span class="p">([</span><span class="n">video_url</span><span class="p">],</span> <span class="n">audio_save_directory</span><span class="p">),</span>
            <span class="n">OpenAIWhisperParser</span><span class="p">()</span>
        <span class="p">)</span>

        <span class="c1"># Load the document (transcription)</span>
        <span class="n">youtube_documents</span> <span class="o">=</span> <span class="n">youtube_loader</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>

        <span class="c1"># Access the transcribed content</span>
        <span class="n">transcribed_text</span> <span class="o">=</span> <span class="n">youtube_documents</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">page_content</span>

        <span class="c1"># Perform sentiment analysis using TextBlob</span>
        <span class="n">blob</span> <span class="o">=</span> <span class="n">TextBlob</span><span class="p">(</span><span class="n">transcribed_text</span><span class="p">)</span>
        <span class="n">polarity</span> <span class="o">=</span> <span class="n">blob</span><span class="o">.</span><span class="n">sentiment</span><span class="o">.</span><span class="n">polarity</span>

        <span class="c1"># Determine sentiment evaluation</span>
        <span class="k">if</span> <span class="n">polarity</span> <span class="o">&gt;</span> <span class="mf">0.1</span><span class="p">:</span>
            <span class="n">sentiment_evaluation</span> <span class="o">=</span> <span class="s2">&quot;positive&quot;</span>
        <span class="k">elif</span> <span class="n">polarity</span> <span class="o">&lt;</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">:</span>
            <span class="n">sentiment_evaluation</span> <span class="o">=</span> <span class="s2">&quot;negative&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">sentiment_evaluation</span> <span class="o">=</span> <span class="s2">&quot;neutral&quot;</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Polarity: </span><span class="si">{</span><span class="n">polarity</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sentiment evaluation: </span><span class="si">{</span><span class="n">sentiment_evaluation</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">transcribed_text</span><span class="p">,</span> <span class="n">polarity</span><span class="p">,</span> <span class="n">sentiment_evaluation</span>

    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;An error occurred: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>

<span class="c1"># Example usage</span>
<span class="n">video_url</span> <span class="o">=</span> <span class="s2">&quot;https://www.youtube.com/watch?v=example_video_id&quot;</span>
<span class="n">text</span><span class="p">,</span> <span class="n">polarity</span><span class="p">,</span> <span class="n">sentiment</span> <span class="o">=</span> <span class="n">transcribe_and_analyze_sentiment</span><span class="p">(</span><span class="n">video_url</span><span class="p">)</span>
</code></pre></div></p>
<p>6.
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">markdown</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">bs4</span><span class="w"> </span><span class="kn">import</span> <span class="n">BeautifulSoup</span>

<span class="k">def</span><span class="w"> </span><span class="nf">create_notion_dataframe_with_word_count</span><span class="p">(</span><span class="n">directory_path</span><span class="p">):</span>
    <span class="c1"># List to store document data</span>
    <span class="n">documents_data</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Iterate through all Markdown files in the directory</span>
    <span class="k">for</span> <span class="n">filename</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">directory_path</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">filename</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.md&quot;</span><span class="p">):</span>
            <span class="c1"># Construct full file path</span>
            <span class="n">file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">directory_path</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>

            <span class="c1"># Read the Markdown file</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">md_file</span><span class="p">:</span>
                <span class="n">md_content</span> <span class="o">=</span> <span class="n">md_file</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

            <span class="c1"># Convert Markdown to HTML</span>
            <span class="n">html_content</span> <span class="o">=</span> <span class="n">markdown</span><span class="o">.</span><span class="n">markdown</span><span class="p">(</span><span class="n">md_content</span><span class="p">)</span>

            <span class="c1"># Use BeautifulSoup to extract clean text</span>
            <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">html_content</span><span class="p">,</span> <span class="s1">&#39;html.parser&#39;</span><span class="p">)</span>
            <span class="n">clean_text</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">get_text</span><span class="p">()</span>

            <span class="c1"># Count the number of words</span>
            <span class="n">word_count</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">clean_text</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>

            <span class="c1"># Extract title (first line with # or filename)</span>
            <span class="n">title</span> <span class="o">=</span> <span class="n">filename</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;.md&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span>
            <span class="n">lines</span> <span class="o">=</span> <span class="n">md_content</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;#&#39;</span><span class="p">):</span>
                    <span class="n">title</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">(</span><span class="s1">&#39;#&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
                    <span class="k">break</span>

            <span class="c1"># Add data to the list</span>
            <span class="n">documents_data</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s1">&#39;filename&#39;</span><span class="p">:</span> <span class="n">filename</span><span class="p">,</span>
                <span class="s1">&#39;title&#39;</span><span class="p">:</span> <span class="n">title</span><span class="p">,</span>
                <span class="s1">&#39;word_count&#39;</span><span class="p">:</span> <span class="n">word_count</span><span class="p">,</span>
                <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="n">clean_text</span><span class="p">[:</span><span class="mi">100</span><span class="p">]</span> <span class="o">+</span> <span class="s1">&#39;...&#39;</span>  <span class="c1"># First 100 characters for preview</span>
            <span class="p">})</span>

    <span class="c1"># Create DataFrame</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">documents_data</span><span class="p">)</span>

    <span class="c1"># Sort by word count in descending order</span>
    <span class="n">df_sorted</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;word_count&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># Print titles of the top 3 longest documents</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Titles of the top 3 longest documents:&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">df_sorted</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">. </span><span class="si">{</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;title&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;word_count&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> words)&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">df_sorted</span>

<span class="c1"># Example usage</span>
<span class="n">directory_path</span> <span class="o">=</span> <span class="s2">&quot;path/to/your/notion/data&quot;</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">create_notion_dataframe_with_word_count</span><span class="p">(</span><span class="n">directory_path</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</code></pre></div></p>
<p>7.
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">requests</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">bs4</span><span class="w"> </span><span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">re</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">nltk</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">nltk.tokenize</span><span class="w"> </span><span class="kn">import</span> <span class="n">sent_tokenize</span>

<span class="c1"># Download necessary NLTK data</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;punkt&#39;</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">load_and_summarize_web_content</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># Get content from URL</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
        <span class="n">response</span><span class="o">.</span><span class="n">raise_for_status</span><span class="p">()</span>  <span class="c1"># Raises HTTPError for 4xx, 5xx status codes</span>

        <span class="c1"># Use BeautifulSoup to parse HTML content</span>
        <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="s1">&#39;html.parser&#39;</span><span class="p">)</span>

        <span class="c1"># Remove scripts and styles for better cleaning</span>
        <span class="k">for</span> <span class="n">script</span> <span class="ow">in</span> <span class="n">soup</span><span class="p">([</span><span class="s2">&quot;script&quot;</span><span class="p">,</span> <span class="s2">&quot;style&quot;</span><span class="p">]):</span>
            <span class="n">script</span><span class="o">.</span><span class="n">decompose</span><span class="p">()</span>

        <span class="c1"># Get clean text, removing all HTML tags</span>
        <span class="n">clean_text</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">get_text</span><span class="p">(</span><span class="n">separator</span><span class="o">=</span><span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="n">strip</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Clean extra whitespace and line breaks</span>
        <span class="n">clean_text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\s+&#39;</span><span class="p">,</span> <span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="n">clean_text</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>

        <span class="c1"># Tokenize text into sentences using NLTK</span>
        <span class="n">sentences</span> <span class="o">=</span> <span class="n">sent_tokenize</span><span class="p">(</span><span class="n">clean_text</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentences</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">:</span>
            <span class="c1"># Create simple summary from first and last sentences</span>
            <span class="n">summary</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;First sentence: </span><span class="si">{</span><span class="n">sentences</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">Last sentence: </span><span class="si">{</span><span class="n">sentences</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentences</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">summary</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Single sentence: </span><span class="si">{</span><span class="n">sentences</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">summary</span> <span class="o">=</span> <span class="s2">&quot;Could not extract sentences from the text.&quot;</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Simple page summary:&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">summary</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">summary</span>

    <span class="k">except</span> <span class="n">requests</span><span class="o">.</span><span class="n">exceptions</span><span class="o">.</span><span class="n">RequestException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Request failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">None</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;An error occurred during parsing: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">None</span>

<span class="c1"># Example usage</span>
<span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;https://example.com&quot;</span>
<span class="n">summary</span> <span class="o">=</span> <span class="n">load_and_summarize_web_content</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
</code></pre></div></p>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.sections", "toc.integrate", "navigation.top", "search.suggest", "search.highlight", "content.tabs.link", "content.code.annotation", "content.code.copy"], "search": "../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.92b07e13.min.js"></script>
      
    
  </body>
</html>