
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.17">
    
    
      
        <title>Answers 2.6 - LLMOps. Make AI Work For You.</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.7e37652d.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#answers-26" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="LLMOps. Make AI Work For You." class="md-header__button md-logo" aria-label="LLMOps. Make AI Work For You." data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            LLMOps. Make AI Work For You.
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Answers 2.6
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
      <div class="md-header__option">
  <div class="md-select">
    
    <button class="md-header__button md-icon" aria-label="Select language">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m12.87 15.07-2.54-2.51.03-.03A17.5 17.5 0 0 0 14.07 6H17V4h-7V2H8v2H1v2h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2zm-2.62 7 1.62-4.33L19.12 17z"/></svg>
    </button>
    <div class="md-select__inner">
      <ul class="md-select__list">
        
          <li class="md-select__item">
            <a href="../../en/" hreflang="en" class="md-select__link">
              English
            </a>
          </li>
        
          <li class="md-select__item">
            <a href="../../ru/" hreflang="ru" class="md-select__link">
              Русский
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</div>
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/boramorka/LLM-book" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    boramorka/LLM-book
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



  

<nav class="md-nav md-nav--primary md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="LLMOps. Make AI Work For You." class="md-nav__button md-logo" aria-label="LLMOps. Make AI Work For You." data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    LLMOps. Make AI Work For You.
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/boramorka/LLM-book" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    boramorka/LLM-book
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="answers-26">Answers 2.6</h1>
<h2 id="theory">Theory</h2>
<ol>
<li>The three main stages involved in the question answering process of a RAG system are Query Reception, Document Retrieval, and Answer Generation.</li>
<li>The limitations of passing all retrieved chunks into the LM's context window include constraints on the context window size, leading to potential loss of relevant information. Strategies to overcome this constraint include MapReduce and Refine, which allow for the aggregation or sequential refinement of information from multiple documents.</li>
<li>The significance of using a Vector Database (VectorDB) in document retrieval for RAG systems lies in its ability to efficiently store and retrieve document embeddings, facilitating the quick and accurate retrieval of documents relevant to a user's query.</li>
<li>The RetrievalQA chain combines document retrieval with question answering by utilizing language models to generate responses based on the content of retrieved documents, thereby enhancing the relevance and accuracy of answers provided to users.</li>
<li>The MapReduce technique is designed for aggregating information from multiple documents quickly, while the Refine technique allows for the sequential refinement of an answer, making it more suitable for tasks requiring high accuracy and iterative improvement. The choice between them depends on the specific requirements of the task at hand.</li>
<li>Practical considerations when implementing MapReduce or Refine techniques in a distributed system include paying attention to network latency and data serialization costs to ensure efficient data transfer and processing, which can significantly impact overall performance.</li>
<li>Experimenting with both MapReduce and Refine techniques is crucial in a RAG system because their effectiveness can vary based on the nature of the data and the specifics of the question-answering task, and experimentation helps determine which technique yields the best results for a particular application.</li>
<li>A major limitation of RetrievalQA chains is their inability to preserve conversational history, which impacts the flow of follow-up queries by making it challenging to maintain context and coherence in ongoing conversations.</li>
<li>Integrating conversational memory into RAG systems is important because it enables the system to remember previous interactions, enhancing the system's ability to engage in meaningful dialogues with users by providing context-aware responses.</li>
<li>Recommended areas for further reading and exploration include the latest advancements in language model technologies, their implications for RAG systems, and additional strategies for integrating conversational memory into RAG frameworks to advance understanding and implementation of sophisticated AI-driven interactions.</li>
</ol>
<h2 id="practice">Practice</h2>
<p>1.
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">langchain.vectorstores</span><span class="w"> </span><span class="kn">import</span> <span class="n">Chroma</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">OpenAIEmbeddings</span>

<span class="k">def</span><span class="w"> </span><span class="nf">initialize_vector_database</span><span class="p">(</span><span class="n">directory_path</span><span class="p">):</span>
    <span class="c1"># Initialize the embeddings generator using OpenAI&#39;s embeddings</span>
    <span class="n">embeddings_generator</span> <span class="o">=</span> <span class="n">OpenAIEmbeddings</span><span class="p">()</span>

    <span class="c1"># Initialize the vector database with the specified storage directory and embedding function</span>
    <span class="n">vector_database</span> <span class="o">=</span> <span class="n">Chroma</span><span class="p">(</span><span class="n">persist_directory</span><span class="o">=</span><span class="n">directory_path</span><span class="p">,</span> <span class="n">embedding_function</span><span class="o">=</span><span class="n">embeddings_generator</span><span class="p">)</span>

    <span class="c1"># Display the current document count in the vector database to verify initialization</span>
    <span class="n">document_count</span> <span class="o">=</span> <span class="n">vector_database</span><span class="o">.</span><span class="n">_collection</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>  <span class="c1"># Assuming the Chroma implementation provides a count method</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Document Count in VectorDB: </span><span class="si">{</span><span class="n">document_count</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Example usage:</span>
<span class="n">documents_storage_directory</span> <span class="o">=</span> <span class="s1">&#39;path/to/your/directory&#39;</span>
<span class="n">initialize_vector_database</span><span class="p">(</span><span class="n">documents_storage_directory</span><span class="p">)</span>
</code></pre></div></p>
<p>2.
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">langchain.vectorstores</span><span class="w"> </span><span class="kn">import</span> <span class="n">Chroma</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">OpenAIEmbeddings</span><span class="p">,</span> <span class="n">ChatOpenAI</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain.chains</span><span class="w"> </span><span class="kn">import</span> <span class="n">RetrievalQA</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain.prompts</span><span class="w"> </span><span class="kn">import</span> <span class="n">PromptTemplate</span>

<span class="k">def</span><span class="w"> </span><span class="nf">setup_retrieval_qa_chain</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">documents_storage_directory</span><span class="p">):</span>
    <span class="c1"># Initialize the embeddings generator and vector database</span>
    <span class="n">embeddings_generator</span> <span class="o">=</span> <span class="n">OpenAIEmbeddings</span><span class="p">()</span>
    <span class="n">vector_database</span> <span class="o">=</span> <span class="n">Chroma</span><span class="p">(</span><span class="n">persist_directory</span><span class="o">=</span><span class="n">documents_storage_directory</span><span class="p">,</span> <span class="n">embedding_function</span><span class="o">=</span><span class="n">embeddings_generator</span><span class="p">)</span>

    <span class="c1"># Initialize the language model</span>
    <span class="n">language_model</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># Custom prompt template</span>
    <span class="n">custom_prompt_template</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;To better assist with the inquiry, consider the details provided below as your reference...</span>
<span class="si">{context}</span>
<span class="s2">Inquiry: </span><span class="si">{question}</span>
<span class="s2">Insightful Response:&quot;&quot;&quot;</span>

    <span class="c1"># Initialize the RetrievalQA chain</span>
    <span class="n">question_answering_chain</span> <span class="o">=</span> <span class="n">RetrievalQA</span><span class="o">.</span><span class="n">from_chain_type</span><span class="p">(</span>
        <span class="n">language_model</span><span class="p">,</span>
        <span class="n">retriever</span><span class="o">=</span><span class="n">vector_database</span><span class="o">.</span><span class="n">as_retriever</span><span class="p">(),</span>
        <span class="n">return_source_documents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">chain_type_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;prompt&quot;</span><span class="p">:</span> <span class="n">PromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span><span class="n">custom_prompt_template</span><span class="p">)}</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">question_answering_chain</span>

<span class="c1"># Example usage:</span>
<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;gpt-4o-mini&quot;</span>
<span class="n">documents_storage_directory</span> <span class="o">=</span> <span class="s1">&#39;path/to/your/documents&#39;</span>
<span class="n">qa_chain</span> <span class="o">=</span> <span class="n">setup_retrieval_qa_chain</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">documents_storage_directory</span><span class="p">)</span>
</code></pre></div></p>
<p>3.
<div class="highlight"><pre><span></span><code><span class="c1"># Assuming the `setup_retrieval_qa_chain` function is defined in the same script or imported</span>

<span class="c1"># Setup for both techniques using the same model and document storage directory</span>
<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;gpt-3.5-turbo&quot;</span>
<span class="n">documents_storage_directory</span> <span class="o">=</span> <span class="s1">&#39;path/to/your/documents&#39;</span>
<span class="n">qa_chain</span> <span class="o">=</span> <span class="n">setup_retrieval_qa_chain</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">documents_storage_directory</span><span class="p">)</span>

<span class="c1"># Configure the question answering chains for MapReduce and Refine</span>
<span class="n">question_answering_chain_map_reduce</span> <span class="o">=</span> <span class="n">RetrievalQA</span><span class="o">.</span><span class="n">from_chain_type</span><span class="p">(</span>
    <span class="n">qa_chain</span><span class="o">.</span><span class="n">language_model</span><span class="p">,</span>
    <span class="n">retriever</span><span class="o">=</span><span class="n">qa_chain</span><span class="o">.</span><span class="n">retriever</span><span class="p">,</span>
    <span class="n">chain_type</span><span class="o">=</span><span class="s2">&quot;map_reduce&quot;</span>
<span class="p">)</span>

<span class="n">question_answering_chain_refine</span> <span class="o">=</span> <span class="n">RetrievalQA</span><span class="o">.</span><span class="n">from_chain_type</span><span class="p">(</span>
    <span class="n">qa_chain</span><span class="o">.</span><span class="n">language_model</span><span class="p">,</span>
    <span class="n">retriever</span><span class="o">=</span><span class="n">qa_chain</span><span class="o">.</span><span class="n">retriever</span><span class="p">,</span>
    <span class="n">chain_type</span><span class="o">=</span><span class="s2">&quot;refine&quot;</span>
<span class="p">)</span>

<span class="c1"># Sample query</span>
<span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;What is the importance of probability in machine learning?&quot;</span>

<span class="c1"># Execute the MapReduce technique</span>
<span class="n">response_map_reduce</span> <span class="o">=</span> <span class="n">question_answering_chain_map_reduce</span><span class="p">({</span><span class="s2">&quot;query&quot;</span><span class="p">:</span> <span class="n">query</span><span class="p">})</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MapReduce Answer:&quot;</span><span class="p">,</span> <span class="n">response_map_reduce</span><span class="p">[</span><span class="s2">&quot;result&quot;</span><span class="p">])</span>

<span class="c1"># Execute the Refine technique</span>
<span class="n">response_refine</span> <span class="o">=</span> <span class="n">question_answering_chain_refine</span><span class="p">({</span><span class="s2">&quot;query&quot;</span><span class="p">:</span> <span class="n">query</span><span class="p">})</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Refine Answer:&quot;</span><span class="p">,</span> <span class="n">response_refine</span><span class="p">[</span><span class="s2">&quot;result&quot;</span><span class="p">])</span>
</code></pre></div></p>
<p>4.
<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">handle_conversational_context</span><span class="p">(</span><span class="n">initial_query</span><span class="p">,</span> <span class="n">follow_up_query</span><span class="p">,</span> <span class="n">qa_chain</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Simulates the handling of a follow-up question in a conversational context.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    - initial_query: The first user query.</span>
<span class="sd">    - follow_up_query: The follow-up user query.</span>
<span class="sd">    - qa_chain: An initialized question answering chain.</span>

<span class="sd">    Returns: None. Prints the responses to both queries.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Generate a response to the initial query</span>
    <span class="n">initial_response</span> <span class="o">=</span> <span class="n">qa_chain</span><span class="p">({</span><span class="s2">&quot;query&quot;</span><span class="p">:</span> <span class="n">initial_query</span><span class="p">})</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Response to Initial Query:&quot;</span><span class="p">,</span> <span class="n">initial_response</span><span class="p">[</span><span class="s2">&quot;result&quot;</span><span class="p">])</span>

    <span class="c1"># Generate a response to the follow-up query</span>
    <span class="n">follow_up_response</span> <span class="o">=</span> <span class="n">qa_chain</span><span class="p">({</span><span class="s2">&quot;query&quot;</span><span class="p">:</span> <span class="n">follow_up_query</span><span class="p">})</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Response to Follow-Up Query:&quot;</span><span class="p">,</span> <span class="n">follow_up_response</span><span class="p">[</span><span class="s2">&quot;result&quot;</span><span class="p">])</span>

<span class="c1"># Example usage (assuming a question_answering_chain like the one set up previously):</span>
<span class="n">initial_query</span> <span class="o">=</span> <span class="s2">&quot;What is the significance of probability in statistics?&quot;</span>
<span class="n">follow_up_query</span> <span class="o">=</span> <span class="s2">&quot;How does it apply to real-world problems?&quot;</span>
<span class="c1"># handle_conversational_context(initial_query, follow_up_query, question_answering_chain)</span>
</code></pre></div></p>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.sections", "toc.integrate", "navigation.top", "search.suggest", "search.highlight", "content.tabs.link", "content.code.annotation", "content.code.copy"], "search": "../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.92b07e13.min.js"></script>
      
    
  </body>
</html>