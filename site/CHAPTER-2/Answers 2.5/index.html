
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../Answers%202.4/">
      
      
        <link rel="next" href="../Answers%202.6/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.5.12">
    
    
      
        <title>2.5 Semantic Search. Advanced Retrieval Strategies - LLMOps. Make AI Work For You.</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.7e359304.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#answers-25" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="LLMOps. Make AI Work For You." class="md-header__button md-logo" aria-label="LLMOps. Make AI Work For You." data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            LLMOps. Make AI Work For You.
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              2.5 Semantic Search. Advanced Retrieval Strategies
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/boramorka/LLM-book" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    boramorka/LLM-book
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



  

<nav class="md-nav md-nav--primary md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="LLMOps. Make AI Work For You." class="md-nav__button md-logo" aria-label="LLMOps. Make AI Work For You." data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    LLMOps. Make AI Work For You.
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/boramorka/LLM-book" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    boramorka/LLM-book
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  <span class="md-ellipsis">
    CHAPTER-1. OPEN AI API
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            CHAPTER-1. OPEN AI API
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CHAPTER-1/1.1%20Introduction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1.1 Introduction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CHAPTER-1/1.2%20Classification/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1.2 Classification
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CHAPTER-1/1.3%20Advanced%20Moderaton/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1.3 Advanced Moderaton
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CHAPTER-1/1.4%20Elevating%20Machine%20Reasoning%3A%20Advanced%20Strategies/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1.4 Elevating Machine Reasoning
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CHAPTER-1/1.5%20The%20Power%20of%20Prompt%20Chaining/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1.5 The Power of Prompt Chaining
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CHAPTER-1/1.6%20Building%20and%20Evaluating%20LLM%20Applications/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1.6 Building and Evaluating LLM Applications
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CHAPTER-1/1.7%20Summary%20and%20Reflections/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1.7 Summary and Reflections
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    CHAPTER-2. LANGCHAIN
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            CHAPTER-2. LANGCHAIN
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2.1%20Introduction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2.1 Introduction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2.2%20LangChain%20Document%20Loaders/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2.2 LangChain Document Loaders
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2.3%20Deep%20Dive%20into%20Text%20Splitting/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2.3 Deep Dive into Text Splitting
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2.4%20The%20Power%20of%20Embeddings/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2.4 The Power of Embeddings
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2.5%20Semantic%20Search.%20Advanced%20Retrieval%20Strategies/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2.5 Semantic Search. Advanced Retrieval Strategies
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2.6%20RAG%20Systems.%20Techniques%20for%20Question%20Answering/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2.6 RAG Systems. Techniques for Question Answering
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2.7%20Building%20Chatbots%20with%20LangChain/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2.7 Building Chatbots with LangChain
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2.8%20Summary%20and%20Reflections/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2.8 Summary and Reflections
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="">
            
  
  <span class="md-ellipsis">
    CHAPTER-3. LLMOPS
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            CHAPTER-3. LLMOPS
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CHAPTER-3/3.1%20Introduction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.1 Introduction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CHAPTER-3/3.2%20Mastering%20LLM%20Workflows%20with%20Kubeflow%20Pipelines/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.2 Mastering LLM Workflows with Kubeflow Pipelines
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CHAPTER-3/3.3%20Implementing%20the%20AI%20Quiz%20Generation%20Mechanism/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.3 Implementing the AI Quiz Generation Mechanism
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CHAPTER-3/3.4%20Summary%20and%20Reflections/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.4 Summary and Reflections
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" checked>
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Answers
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Answers
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CHAPTER-1/Answers%201.1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1.1 Introduction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CHAPTER-1/Answers%201.2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1.2 Classification
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CHAPTER-1/Answers%201.3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1.3 Advanced Moderaton
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CHAPTER-1/Answers%201.4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1.4 Elevating Machine Reasoning
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CHAPTER-1/Answers%201.5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1.5 The Power of Prompt Chaining
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CHAPTER-1/Answers%201.6/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1.6 Building and Evaluating LLM Applications
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Answers%202.2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2.2 LangChain Document Loaders
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Answers%202.3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2.3 Deep Dive into Text Splitting
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Answers%202.4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2.4 The Power of Embeddings
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    2.5 Semantic Search. Advanced Retrieval Strategies
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    2.5 Semantic Search. Advanced Retrieval Strategies
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#theory" class="md-nav__link">
    <span class="md-ellipsis">
      Theory
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#practice" class="md-nav__link">
    <span class="md-ellipsis">
      Practice
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Answers%202.6/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2.6 RAG Systems. Techniques for Question Answering
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Answers%202.7/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2.7 Building Chatbots with LangChain
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CHAPTER-3/Answers%203.2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.2 Mastering LLM Workflows with Kubeflow Pipelines
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CHAPTER-3/Answers%203.3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.3 Implementing the AI Quiz Generation Mechanism
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


<h1 id="answers-25">Answers 2.5</h1>
<h2 id="theory">Theory</h2>
<ol>
<li>Maximum Marginal Relevance (MMR) is designed to optimize the balance between relevance and diversity in document retrieval. It selects documents that are both closely related to the query and dissimilar from one another, enhancing the breadth of information provided.</li>
<li>Self-query retrieval efficiently processes queries that involve both semantic content and specific metadata by splitting the query into semantic and metadata components, enabling precise and contextually relevant search results.</li>
<li>Contextual compression targets the extraction of the most relevant segments from documents, focusing on the essence of the information needed to answer a query, thereby improving the quality of responses and reducing unnecessary computational burden.</li>
<li>Setting up an environment involves loading necessary libraries, configuring access to APIs (such as OpenAI's API for embeddings), and initializing a vector database. This foundational step ensures that the system is equipped to perform advanced retrieval functions effectively.</li>
<li>Initializing a vector database involves embedding textual content into a high-dimensional space to facilitate efficient semantic similarity searches. This setup allows for rapid and accurate retrieval of documents based on their semantic closeness to a query.</li>
<li>Populating a vector database involves adding textual content and then using similarity search to find documents closely related to a query. Diverse search, enabled by MMR, further refines results to ensure a broad spectrum of information is covered.</li>
<li>Using MMR in document retrieval enhances diversity by preventing the clustering of similar documents in search results. This approach ensures a wider range of perspectives and information, making the retrieval process more informative and less redundant.</li>
<li>Metadata enhances search specificity by allowing for searches that go beyond semantic content, targeting specific document attributes (such as publication date or document type), resulting in more precise and relevant search outcomes.</li>
<li>Self-query retrievers automate the extraction of both semantic queries and relevant metadata from user inputs, simplifying the search process and making it more user-friendly, while ensuring that results are accurately tailored to the query's context.</li>
<li>Contextual compression improves retrieval efficiency by focusing on the most pertinent segments of documents, which not only streamlines the information presented to users but also conserves computational resources by reducing the data volume processed.</li>
<li>Best practices include a balanced application of MMR for diversity, effective use of metadata for specificity, optimization of contextual compression to balance information relevance and computational efficiency, and strategic preparation of documents for retrieval.</li>
<li>Vector-based methods are highly effective for semantic similarity searches but may lack specificity in certain contexts. Alternative methods like TF-IDF and SVM offer different advantages, such as better handling of specific keyword-based searches or categorization tasks.</li>
<li>The integration of advanced retrieval techniques significantly enhances semantic search systems by delivering more precise, diverse, and contextually relevant information, which improves the overall user experience in interacting with intelligent systems.</li>
<li>The ongoing development of NLP technologies promises further enhancements in retrieval techniques, potentially introducing more sophisticated methods for understanding and responding to complex queries, thereby maintaining the progression towards more intelligent and intuitive search capabilities.</li>
</ol>
<h2 id="practice">Practice</h2>
<ol>
<li>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Tuple</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># Placeholder for the OpenAI embedding function</span>
<span class="k">def</span> <span class="nf">openai_embedding</span><span class="p">(</span><span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]:</span>
    <span class="c1"># This function would call the OpenAI API to get the embeddings for the text</span>
    <span class="c1"># For demonstration purposes, returning a random vector</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">768</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

<span class="c1"># Placeholder similarity function that calculates the cosine similarity between two vectors</span>
<span class="k">def</span> <span class="nf">cosine_similarity</span><span class="p">(</span><span class="n">vec1</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span> <span class="n">vec2</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="c1"># Convert lists to numpy arrays</span>
    <span class="n">vec1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">vec1</span><span class="p">)</span>
    <span class="n">vec2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">vec2</span><span class="p">)</span>
    <span class="c1"># Calculate cosine similarity</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">vec1</span><span class="p">,</span> <span class="n">vec2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">vec1</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">vec2</span><span class="p">))</span>

<span class="k">class</span> <span class="nc">VectorDatabase</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">persist_directory</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">persist_directory</span> <span class="o">=</span> <span class="n">persist_directory</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">database</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># This will store tuples of (text, embedding)</span>

    <span class="k">def</span> <span class="nf">add_text</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="c1"># Generate embedding for the text</span>
        <span class="n">embedding</span> <span class="o">=</span> <span class="n">openai_embedding</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
        <span class="c1"># Store the text and its embedding in the database</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">database</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">text</span><span class="p">,</span> <span class="n">embedding</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">similarity_search</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">k</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="n">query_embedding</span> <span class="o">=</span> <span class="n">openai_embedding</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
        <span class="c1"># Calculate similarity scores for all documents in the database</span>
        <span class="n">similarities</span> <span class="o">=</span> <span class="p">[(</span><span class="n">text</span><span class="p">,</span> <span class="n">cosine_similarity</span><span class="p">(</span><span class="n">query_embedding</span><span class="p">,</span> <span class="n">embedding</span><span class="p">))</span> <span class="k">for</span> <span class="n">text</span><span class="p">,</span> <span class="n">embedding</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">database</span><span class="p">]</span>
        <span class="c1"># Sort documents based on similarity scores in descending order</span>
        <span class="n">sorted_similarities</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">similarities</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="c1"># Return the top k most similar texts</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">text</span> <span class="k">for</span> <span class="n">text</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">sorted_similarities</span><span class="p">[:</span><span class="n">k</span><span class="p">]]</span>

<span class="c1"># Example usage</span>
<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="c1"># Initialize the vector database with a dummy directory path</span>
    <span class="n">vector_db</span> <span class="o">=</span> <span class="n">VectorDatabase</span><span class="p">(</span><span class="s2">&quot;path/to/persist/directory&quot;</span><span class="p">)</span>

    <span class="c1"># Add some texts to the database</span>
    <span class="n">vector_db</span><span class="o">.</span><span class="n">add_text</span><span class="p">(</span><span class="s2">&quot;The quick brown fox jumps over the lazy dog.&quot;</span><span class="p">)</span>
    <span class="n">vector_db</span><span class="o">.</span><span class="n">add_text</span><span class="p">(</span><span class="s2">&quot;Lorem ipsum dolor sit amet, consectetur adipiscing elit.&quot;</span><span class="p">)</span>
    <span class="n">vector_db</span><span class="o">.</span><span class="n">add_text</span><span class="p">(</span><span class="s2">&quot;Python is a popular programming language for data science.&quot;</span><span class="p">)</span>

    <span class="c1"># Perform a similarity search</span>
    <span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;Programming in Python&quot;</span>
    <span class="n">similar_texts</span> <span class="o">=</span> <span class="n">vector_db</span><span class="o">.</span><span class="n">similarity_search</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Similarity Search Results:&quot;</span><span class="p">,</span> <span class="n">similar_texts</span><span class="p">)</span>
</code></pre></div>
</li>
<li>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">compress_segment</span><span class="p">(</span><span class="n">segment</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">query</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="c1"># Placeholder for an external utility function that compresses a segment based on the query</span>
    <span class="c1"># This should return a shorter version of the segment that&#39;s relevant to the query</span>
    <span class="k">return</span> <span class="n">segment</span><span class="p">[:</span><span class="nb">len</span><span class="p">(</span><span class="n">segment</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">]</span>  <span class="c1"># Mock implementation</span>

<span class="k">def</span> <span class="nf">compress_document</span><span class="p">(</span><span class="n">document</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">query</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
    <span class="n">compressed_document</span> <span class="o">=</span> <span class="p">[</span><span class="n">compress_segment</span><span class="p">(</span><span class="n">segment</span><span class="p">,</span> <span class="n">query</span><span class="p">)</span> <span class="k">for</span> <span class="n">segment</span> <span class="ow">in</span> <span class="n">document</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">compressed_document</span>

<span class="c1"># Example usage of compress_document</span>
<span class="n">document</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;The first chapter introduces the concepts of machine learning.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Machine learning techniques are varied and serve different purposes.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;In the context of data analysis, regression models can predict continuous outcomes.&quot;</span>
<span class="p">]</span>
<span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;machine learning&quot;</span>
<span class="n">compressed_doc</span> <span class="o">=</span> <span class="n">compress_document</span><span class="p">(</span><span class="n">document</span><span class="p">,</span> <span class="n">query</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Compressed Document Segments:&quot;</span><span class="p">,</span> <span class="n">compressed_doc</span><span class="p">)</span>
</code></pre></div>
</li>
<li>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">similarity</span><span class="p">(</span><span class="n">doc_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">query</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="c1"># Placeholder function to compute similarity between a document and a query</span>
    <span class="k">return</span> <span class="mf">0.5</span>  <span class="c1"># Mock implementation</span>

<span class="k">def</span> <span class="nf">diversity</span><span class="p">(</span><span class="n">doc_id1</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">doc_id2</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="c1"># Placeholder function to compute diversity between two documents</span>
    <span class="k">return</span> <span class="mf">0.5</span>  <span class="c1"># Mock implementation</span>

<span class="k">def</span> <span class="nf">max_marginal_relevance</span><span class="p">(</span><span class="n">doc_ids</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">query</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">lambda_param</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">k</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
    <span class="n">selected</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">remaining</span> <span class="o">=</span> <span class="n">doc_ids</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

    <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">selected</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">k</span> <span class="ow">and</span> <span class="n">remaining</span><span class="p">:</span>
        <span class="n">mmr_scores</span> <span class="o">=</span> <span class="p">{</span><span class="n">doc_id</span><span class="p">:</span> <span class="n">lambda_param</span> <span class="o">*</span> <span class="n">similarity</span><span class="p">(</span><span class="n">doc_id</span><span class="p">,</span> <span class="n">query</span><span class="p">)</span> <span class="o">-</span> 
                      <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">lambda_param</span><span class="p">)</span> <span class="o">*</span> <span class="nb">max</span><span class="p">([</span><span class="n">diversity</span><span class="p">(</span><span class="n">doc_id</span><span class="p">,</span> <span class="n">sel</span><span class="p">)</span> <span class="k">for</span> <span class="n">sel</span> <span class="ow">in</span> <span class="n">selected</span><span class="p">]</span> <span class="ow">or</span> <span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                      <span class="k">for</span> <span class="n">doc_id</span> <span class="ow">in</span> <span class="n">remaining</span><span class="p">}</span>
        <span class="n">next_selected</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">mmr_scores</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">mmr_scores</span><span class="o">.</span><span class="n">get</span><span class="p">)</span>
        <span class="n">selected</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">next_selected</span><span class="p">)</span>
        <span class="n">remaining</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">next_selected</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">selected</span>

<span class="c1"># Example usage of max_marginal_relevance</span>
<span class="n">doc_ids</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;doc1&quot;</span><span class="p">,</span> <span class="s2">&quot;doc2&quot;</span><span class="p">,</span> <span class="s2">&quot;doc3&quot;</span><span class="p">]</span>
<span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;data analysis&quot;</span>
<span class="n">selected_docs</span> <span class="o">=</span> <span class="n">max_marginal_relevance</span><span class="p">(</span><span class="n">doc_ids</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Selected Documents:&quot;</span><span class="p">,</span> <span class="n">selected_docs</span><span class="p">)</span>
</code></pre></div>
</li>
<li>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">initialize_vector_db</span><span class="p">():</span>
    <span class="c1"># Initialize vector database</span>
    <span class="n">vector_db</span> <span class="o">=</span> <span class="n">VectorDatabase</span><span class="p">(</span><span class="s2">&quot;path/to/persist/directory&quot;</span><span class="p">)</span>

    <span class="c1"># Define some example texts</span>
    <span class="n">texts</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s2">&quot;The quick brown fox jumps over the lazy dog.&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Lorem ipsum dolor sit amet, consectetur adipiscing elit.&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Python is a popular programming language for data science.&quot;</span>
    <span class="p">]</span>

    <span class="c1"># Populate the database with texts</span>
    <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">texts</span><span class="p">:</span>
        <span class="n">vector_db</span><span class="o">.</span><span class="n">add_text</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

    <span class="c1"># Perform a similarity search</span>
    <span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;data science&quot;</span>
    <span class="n">similar_texts</span> <span class="o">=</span> <span class="n">vector_db</span><span class="o">.</span><span class="n">similarity_search</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Similarity Search Results:&quot;</span><span class="p">,</span> <span class="n">similar_texts</span><span class="p">)</span>

    <span class="c1"># For demonstration of diverse search, let&#39;s reuse similar_texts with a comment explaining the intention</span>
    <span class="c1"># In a real scenario, this would involve applying MMR or another diversity enhancing method</span>
    <span class="c1"># This is just to illustrate how one might call such a function after its implementation</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Diverse Search Results (simulated):&quot;</span><span class="p">,</span> <span class="n">similar_texts</span><span class="p">)</span>

<span class="c1"># Run the demonstration</span>
<span class="n">initialize_vector_db</span><span class="p">()</span>
</code></pre></div>
</li>
</ol>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var tab,labels=set.querySelector(".tabbed-labels");for(tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.sections", "toc.integrate", "navigation.top", "search.suggest", "search.highlight", "content.tabs.link", "content.code.annotation", "content.code.copy"], "search": "../../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.c8d2eff1.min.js"></script>
      
    
  </body>
</html>